{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertli/miniconda3/envs/mujoco_sim/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.normal import Normal\n",
    "import pickle\n",
    "import time\n",
    "import gymnasium as gym\n",
    "from segway_sim.envs import SegwayEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ob space: 6\n",
      "ac space: 1\n",
      "Episode: 0 Average Reward: 275\n"
     ]
    }
   ],
   "source": [
    "class PID:\n",
    "    def __init__(self, kp=1, ki=0, kd=0, setpoint=0):\n",
    "        self.kp = kp\n",
    "        self.ki = ki\n",
    "        self.kd = kd\n",
    "        self.setpoint = setpoint\n",
    "        self.integral = 0\n",
    "        self.previous_error = 0\n",
    "    def sample_action(self, obs: np.ndarray) -> float:\n",
    "        error = self.setpoint - obs[0]\n",
    "        self.integral += error\n",
    "        derivative = error - self.previous_error\n",
    "\n",
    "        action = self.kp * error + self.ki * self.integral + self.kd * derivative\n",
    "\n",
    "        self.previous_error = error\n",
    "        action = max(min(action, 0.7), -0.7)\n",
    "        return [action]\n",
    "\n",
    "    def update(self):\n",
    "        return\n",
    "    def save(self, nn_file_path: str):\n",
    "        return\n",
    "\n",
    "env = SegwayEnv(max_ep_len = 1000)\n",
    "wrapped_env = gym.wrappers.RecordEpisodeStatistics(env, 50)  # Records episode-reward\n",
    "# wrapped_env = gym.wrappers.RecordVideo(wrapped_env, 'videos', episode_trigger = lambda x: x % 1000 == 0)\n",
    "\n",
    "obs_space_dims = env.observation_space.shape[0]\n",
    "action_space_dims = env.action_space.shape[0]\n",
    "print('ob space:', obs_space_dims)\n",
    "print('ac space:', action_space_dims)\n",
    "\n",
    "seed = int(time.time())\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "agent = PID(15, 0, 0)\n",
    "reward_over_episodes = []\n",
    "\n",
    "for episode in range(1):\n",
    "    obs, info = wrapped_env.reset(seed=seed)\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.sample_action(obs)\n",
    "        obs, reward, terminated, truncated, info = wrapped_env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    reward_over_episodes.append(wrapped_env.return_queue[-1])\n",
    "    agent.update()\n",
    "\n",
    "    if episode % 1000 == 0:\n",
    "        avg_reward = int(np.mean(wrapped_env.return_queue))\n",
    "        print(\"Episode:\", episode, \"Average Reward:\", avg_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertli/miniconda3/envs/mujoco_sim/lib/python3.9/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/robertli/github/tinySegway/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation [ 1.31828900e-01 -2.11840573e+00  2.39865870e+01 -1.42868453e-03\n",
      " -6.34104121e-03  9.02506296e-03]\n",
      "Box(-1.0, 1.0, (1,), float32)\n",
      "Moviepy - Building video /Users/robertli/github/tinySegway/videos/SegwayPID-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/robertli/github/tinySegway/videos/SegwayPID-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/robertli/github/tinySegway/videos/SegwayPID-episode-0.mp4\n",
      "terminated at 448\n"
     ]
    }
   ],
   "source": [
    "from gymnasium.wrappers import RecordVideo\n",
    "# env = gym.make(\"InvertedPendulum-v4\", render_mode = 'rgb_array')\n",
    "env = SegwayEnv(max_ep_len = 1000, render_mode=\"rgb_array\")\n",
    "video_env = RecordVideo(env, video_folder=\"videos\", name_prefix=\"SegwayPID\")\n",
    "observation, info = video_env.reset()\n",
    "print(\"observation\", observation)\n",
    "print(video_env.action_space)\n",
    "for i in range(1000):\n",
    "    action = agent.sample_action(observation)\n",
    "    # action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = video_env.step(action)\n",
    "    if terminated or truncated:\n",
    "        print(\"terminated at\", i)\n",
    "        break\n",
    "        observation, info = video_env.reset()\n",
    "video_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
