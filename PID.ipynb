{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.normal import Normal\n",
    "import pickle\n",
    "import gymnasium as gym\n",
    "from segway_sim.envs import SegwayEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ob space: 3\n",
      "ac space: 1\n",
      "Episode: 0 Average Reward: 998\n"
     ]
    }
   ],
   "source": [
    "class PID:\n",
    "    def __init__(self, obs_space_dims: int, action_space_dims: int, nn_file_path: str = None):\n",
    "        return\n",
    "    def sample_action(self, obs: np.ndarray) -> float:\n",
    "        angel = obs[0]\n",
    "        # print(angel)\n",
    "        ac = angel * -2\n",
    "        return [ac]\n",
    "\n",
    "    def update(self):\n",
    "        return\n",
    "    def save(self, nn_file_path: str):\n",
    "        return\n",
    "\n",
    "env = SegwayEnv(max_ep_len = 1000)\n",
    "wrapped_env = gym.wrappers.RecordEpisodeStatistics(env, 50)  # Records episode-reward\n",
    "# wrapped_env = gym.wrappers.RecordVideo(wrapped_env, 'videos', episode_trigger = lambda x: x % 1000 == 0)\n",
    "\n",
    "obs_space_dims = env.observation_space.shape[0]\n",
    "action_space_dims = env.action_space.shape[0]\n",
    "print('ob space:', obs_space_dims)\n",
    "print('ac space:', action_space_dims)\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "agent = PID(obs_space_dims, action_space_dims,nn_file_path = 'nn_segway.pkl')\n",
    "reward_over_episodes = []\n",
    "\n",
    "for episode in range(1):\n",
    "    obs, info = wrapped_env.reset(seed=seed)\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.sample_action(obs)\n",
    "        obs, reward, terminated, truncated, info = wrapped_env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    reward_over_episodes.append(wrapped_env.return_queue[-1])\n",
    "    agent.update()\n",
    "\n",
    "    if episode % 1000 == 0:\n",
    "        avg_reward = int(np.mean(wrapped_env.return_queue))\n",
    "        print(\"Episode:\", episode, \"Average Reward:\", avg_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/liz/tinySegway/PID.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/liz/tinySegway/PID.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39msample_action(observation)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/liz/tinySegway/PID.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# action = env.action_space.sample()\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/liz/tinySegway/PID.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m video_env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/liz/tinySegway/PID.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m99\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/liz/tinySegway/PID.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     acc_y\u001b[39m.\u001b[39mappend(observation[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gymnasium/wrappers/record_video.py:183\u001b[0m, in \u001b[0;36mRecordVideo.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecording:\n\u001b[1;32m    182\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvideo_recorder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvideo_recorder\u001b[39m.\u001b[39;49mcapture_frame()\n\u001b[1;32m    184\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecorded_frames \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    185\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvideo_length \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gymnasium/wrappers/monitoring/video_recorder.py:113\u001b[0m, in \u001b[0;36mVideoRecorder.capture_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcapture_frame\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    112\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Render the given `env` and add the resulting frame to the video.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender()\n\u001b[1;32m    114\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(frame, List):\n\u001b[1;32m    115\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m frame\n",
      "File \u001b[0;32m~/tinySegway/segway_sim/envs/mujoco_env.py:409\u001b[0m, in \u001b[0;36mMujocoEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 409\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmujoco_renderer\u001b[39m.\u001b[39;49mrender(\n\u001b[1;32m    410\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender_mode, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcamera_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcamera_name\n\u001b[1;32m    411\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:669\u001b[0m, in \u001b[0;36mMujocoRenderer.render\u001b[0;34m(self, render_mode, camera_id, camera_name)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[39mif\u001b[39;00m camera_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    663\u001b[0m         camera_id \u001b[39m=\u001b[39m mujoco\u001b[39m.\u001b[39mmj_name2id(\n\u001b[1;32m    664\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel,\n\u001b[1;32m    665\u001b[0m             mujoco\u001b[39m.\u001b[39mmjtObj\u001b[39m.\u001b[39mmjOBJ_CAMERA,\n\u001b[1;32m    666\u001b[0m             camera_name,\n\u001b[1;32m    667\u001b[0m         )\n\u001b[0;32m--> 669\u001b[0m     img \u001b[39m=\u001b[39m viewer\u001b[39m.\u001b[39;49mrender(render_mode\u001b[39m=\u001b[39;49mrender_mode, camera_id\u001b[39m=\u001b[39;49mcamera_id)\n\u001b[1;32m    670\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n\u001b[1;32m    672\u001b[0m \u001b[39melif\u001b[39;00m render_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:223\u001b[0m, in \u001b[0;36mOffScreenViewer.render\u001b[0;34m(self, render_mode, camera_id, segmentation)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mfor\u001b[39;00m marker_params \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_markers:\n\u001b[1;32m    221\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_marker_to_scene(marker_params)\n\u001b[0;32m--> 223\u001b[0m mujoco\u001b[39m.\u001b[39;49mmjr_render(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mviewport, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscn, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcon)\n\u001b[1;32m    225\u001b[0m \u001b[39mfor\u001b[39;00m gridpos, (text1, text2) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_overlays\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    226\u001b[0m     mujoco\u001b[39m.\u001b[39mmjr_overlay(\n\u001b[1;32m    227\u001b[0m         mujoco\u001b[39m.\u001b[39mmjtFontScale\u001b[39m.\u001b[39mmjFONTSCALE_150,\n\u001b[1;32m    228\u001b[0m         gridpos,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcon,\n\u001b[1;32m    233\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gymnasium.wrappers import RecordVideo\n",
    "# env = gym.make(\"InvertedPendulum-v4\", render_mode = 'rgb_array')\n",
    "acc_y = []\n",
    "acc_z = []\n",
    "for i in range(1000):\n",
    "    env = SegwayEnv(max_ep_len = 1000, render_mode=\"rgb_array\")\n",
    "    video_env = RecordVideo(env, video_folder=\"videos\", name_prefix=\"Segway\")\n",
    "    observation, info = video_env.reset(seed=seed)\n",
    "    #print(observation)\n",
    "    for i in range(100):\n",
    "        action = agent.sample_action(observation)\n",
    "        # action = env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = video_env.step(action)\n",
    "        if i == 99:\n",
    "            acc_y.append(observation[0])\n",
    "            acc_z.append(observation[1])\n",
    "        if terminated or truncated:\n",
    "            print(\"terminated at\", i)\n",
    "            break\n",
    "            observation, info = video_env.reset()\n",
    "    #video_env.close()\n",
    "np.savetxt(\"acc_x1.txt\", acc_y)\n",
    "np.savetxt(\"acc_y1.txt\", acc_z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
